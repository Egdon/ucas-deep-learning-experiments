
# 实验一 手写数字识别  

## 一、实验目的  
1. 掌握卷积神经网络基本原理；  
2. 掌握 PyTorch（或其他框架）的基本用法以及构建卷积网络的基本操作；  
3. 了解 PyTorch（或其他框架）在 GPU 上的使用方法。  


## 二、实验要求  
1. 搭建 PyTorch（或其他框架）环境；  
2. 构建一个规范的卷积神经网络组织结构；  
3. 在 MNIST 手写数字数据集上进行训练和评估，实现测试集准确率达到 98% 及以上；  
4. 按规定时间在课程网站提交实验报告、代码以及 PPT。  


## 三、实验原理（以 PyTorch 为例）  
### 1. PyTorch 基本用法  
使用 PyTorch 需掌握以下核心内容：  
- 张量的创建与使用  
- 数据创建和数据加载  
- 数据增强  
- 网络模型创建  
- 使用 `torch.autograd` 自动求梯度  
- 模型参数优化  
- 模型加载与保存  

**背景**：PyTorch 前身是 Torch，基于 Python 开发，支持动态图和 GPU 加速，由 Torch7 团队开发，是 Python 优先的深度学习框架。  

### 2. 卷积神经网络  
#### （1）网络结构  
典型卷积神经网络由卷积层、池化层、激活函数层交替组合构成，体现深度学习的“深度”特性。  

#### （2）卷积操作  
- **数学定义**：  
  给定二维图像 \( I \) 和卷积核 \( K \)，卷积运算表示为：  
  \[  
  S(i, j) = (I * K)(i, j) = \sum_{m} \sum_{n} I(i+m, j+n) K(m, n)  
  \]  
- **示例**（5×5 输入矩阵与 3×3 卷积核）：  
  **输入**：  
  ```  
  1 6 5 0 1  
  2 7 4 9 2  
  3 8 3 8 3  
  4 9 2 7 4  
  5 0 6 5  
  ```  
  **输出**：  
  ```  
  20  
  22 22 22  
  14 20 20  
  ```  
- **关键参数**：  
  - `padding`：可选 `valid`（不填充）或 `same`（填充使输出与输入尺寸相同）。  
  - **步长**：控制操作在特征图上的执行间隔。  

#### （3）池化操作  
- **作用**：用相邻区域统计特征作为输出，常用最大池化和均值池化。  
- **特点**：无训练参数，需指定核大小、步长和类型。  
- **示例**：  
  **最大池化输出**：  
  ```  
  24 24  
  20 24 14  
  22 22  
  22 22 22  
  ```  
  **均值池化输出**：  
  ```  
  14 20 20  
  22 20.5  
  19.5 21  
  ```  

#### （4）激活函数层  
- **作用**：为网络引入非线性，增强表达能力，常用函数包括 `sigmoid`、`tanh`、`ReLU`。  


## 四、实验所用工具及数据集  
### 1. 工具  
- Anaconda  
- PyTorch（安装教程：[PyTorch 官网](https://pytorch.org/)）  

### 2. 数据集  
- **MNIST 手写数字数据集**（下载地址：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)）  


## 五、实验步骤与方法（以 PyTorch 为例）  
### 1. 安装环境  
安装 Anaconda、PyTorch，若使用 GPU 需安装 cuda、cudnn。  

### 2. 下载数据集  
获取 MNIST 手写数字数据集。  

### 3. 加载数据  
```python  
# 下载并加载训练集  
train_data = torchvision.datasets.MNIST(  
    root='./data/',  
    train=True,  
    transform=torchvision.transforms.ToTensor()  
)  
# 下载并加载测试集  
test_data = torchvision.datasets.MNIST(  
    root='./data/',  
    train=False  
)  
# 数据加载器（批处理）  
train_loader = Data.DataLoader(  
    dataset=train_data,  
    batch_size=BATCH_SIZE,  
    shuffle=True  
)  
test_loader = Data.DataLoader(  
    dataset=test_data,  
    batch_size=BATCH_SIZE,  
    shuffle=False  
)  
```  

### 4. 构建模型  
```python  
import torch  
import torch.nn as nn  
import torch.nn.functional as F  

class CNN(nn.Module):  
    def __init__(self):  
        super(CNN, self).__init__()  
        # 第一层卷积+激活+池化  
        self.conv1 = nn.Sequential(  
            nn.Conv2d(  
                in_channels=1,       # 输入通道数（MNIST 为灰度图，1通道）  
                out_channels=16,     # 输出通道数（卷积核数量）  
                kernel_size=5,       # 卷积核大小  
                stride=1,            # 步长  
                padding=2            # 填充数，使输出尺寸不变  
            ),  
            nn.ReLU(),            # 激活函数  
            nn.MaxPool2d(2)       # 池化核大小 2x2  
        )  
        # 第二层卷积+激活+池化  
        self.conv2 = nn.Sequential(  
            nn.Conv2d(16, 32, 5, 1, 2),  
            nn.ReLU(),  
            nn.MaxPool2d(2)  
        )  
        # 全连接层  
        self.out = nn.Linear(32 * 7 * 7, 10)  # 输出 10 个类别（0-9）  

    def forward(self, x):  
        x = self.conv1(x)  
        x = self.conv2(x)  
        x = x.view(x.size(0), -1)  # 展平特征图为一维向量  
        output = self.out(x)  
        return output  
```  

### 5. 创建优化器与损失函数  
```python  
optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)  # Adam 优化器  
loss_func = nn.CrossEntropyLoss()  # 交叉熵损失函数（适用于分类任务）  
```  

### 6. 训练与评估模型  
```python  
EPOCH = 10  # 训练轮数  
BATCH_SIZE = 50  # 批大小  

for epoch in range(EPOCH):  
    for step, (b_x, b_y) in enumerate(train_loader):  
        output = cnn(b_x)  
        loss = loss_func(output, b_y)  # 计算损失  
        optimizer.zero_grad()  # 梯度清零  
        loss.backward()  # 反向传播  
        optimizer.step()  # 更新参数  

        # 每 50 步打印训练进度和测试准确率  
        if step % 50 == 0:  
            correct = 0  
            total = 0  
            with torch.no_grad():  # 测试时不计算梯度  
                for test_x, test_y in test_loader:  
                    test_output = cnn(test_x)  
                    pred_y = torch.max(test_output, 1)[1].numpy()  # 预测类别  
                    correct += (pred_y == test_y.numpy()).sum()  
                    total += test_y.size(0)  
            accuracy = correct / total  
            print(f"Epoch: {epoch+1}/{EPOCH} | Step: {step} | Loss: {loss.item():.4f} | Accuracy: {accuracy*100:.2f}%")  

# 保存模型  
torch.save(cnn.state_dict(), "mnist_cnn.pth")  
```  


### Typora 兼容性说明：  
1. **代码块**：使用标准的 Python 语法高亮（```python```），Typora 可正确识别。  
2. **公式**：LaTeX 公式（如卷积公式）在 Typora 中需开启“内联公式”或“代码块”渲染（默认支持）。  
3. **列表与层级**：使用 ## 、### 层级标题，无序列表（- ）和有序列表（数字+点）均兼容 Typora 格式。  
4. **链接**：直接使用 Markdown 标准链接格式（[文本](链接)），Typora 支持点击跳转。  

