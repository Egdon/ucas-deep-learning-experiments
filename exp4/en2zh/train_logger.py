import json
import csv
import os
from datetime import datetime


class TrainingLogger:
    """è®­ç»ƒè¿‡ç¨‹æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_dir="./experiment"):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        
        # åˆå§‹åŒ–è®°å½•æ–‡ä»¶
        self.metrics_file = os.path.join(log_dir, "training_metrics.csv")
        self.detailed_log = os.path.join(log_dir, "training_detailed.json")
        
        # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
        self.training_data = {
            "start_time": datetime.now().isoformat(),
            "epochs": [],
            "config": {}
        }
        
        # åˆ›å»ºCSVæ–‡ä»¶å¹¶å†™å…¥è¡¨å¤´
        self._init_csv()
    
    def _init_csv(self):
        """åˆå§‹åŒ–CSVæ–‡ä»¶"""
        with open(self.metrics_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                'epoch',
                'train_loss', 
                'val_loss',
                'bleu_score',
                'learning_rate',
                'epoch_time',
                'best_bleu',
                'early_stop_count'
            ])
    
    def log_config(self, config_dict):
        """è®°å½•è®­ç»ƒé…ç½®"""
        self.training_data["config"] = config_dict
        self._save_detailed_log()
    
    def log_epoch(self, epoch, train_loss, val_loss, bleu_score, learning_rate, 
                  epoch_time, best_bleu, early_stop_count):
        """è®°å½•æ¯ä¸ªepochçš„è®­ç»ƒæ•°æ®"""
        
        # ç¡®ä¿æ‰€æœ‰æ•°å€¼éƒ½æ˜¯PythonåŸç”Ÿç±»å‹
        def convert_to_python_type(value):
            """å°†PyTorch tensoræˆ–numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹"""
            if hasattr(value, 'item'):  # PyTorch tensor
                return value.item()
            elif hasattr(value, 'tolist'):  # numpy array
                return value.tolist()
            else:
                return float(value)
        
        # è½¬æ¢æ‰€æœ‰æ•°å€¼ç±»å‹
        train_loss = convert_to_python_type(train_loss)
        val_loss = convert_to_python_type(val_loss)
        bleu_score = convert_to_python_type(bleu_score)
        learning_rate = convert_to_python_type(learning_rate)
        epoch_time = convert_to_python_type(epoch_time)
        best_bleu = convert_to_python_type(best_bleu)
        early_stop_count = int(early_stop_count)
        
        # è®°å½•åˆ°CSV
        with open(self.metrics_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                epoch,
                f"{train_loss:.6f}",
                f"{val_loss:.6f}", 
                f"{bleu_score:.4f}",
                f"{learning_rate:.8f}",
                f"{epoch_time:.2f}",
                f"{best_bleu:.4f}",
                early_stop_count
            ])
        
        # è®°å½•åˆ°è¯¦ç»†æ—¥å¿—
        epoch_data = {
            "epoch": int(epoch),
            "train_loss": train_loss,
            "val_loss": val_loss,
            "bleu_score": bleu_score,
            "learning_rate": learning_rate,
            "epoch_time": epoch_time,
            "best_bleu": best_bleu,
            "early_stop_count": early_stop_count,
            "timestamp": datetime.now().isoformat()
        }
        
        self.training_data["epochs"].append(epoch_data)
        self._save_detailed_log()
        
        print(f"ğŸ“Š Epoch {epoch} æ•°æ®å·²è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶")
    
    def log_training_complete(self, total_time, final_bleu, model_path):
        """è®°å½•è®­ç»ƒå®Œæˆä¿¡æ¯"""
        completion_data = {
            "end_time": datetime.now().isoformat(),
            "total_training_time": total_time,
            "final_bleu_score": final_bleu,
            "model_saved_path": model_path,
            "total_epochs": len(self.training_data["epochs"])
        }
        
        self.training_data["training_summary"] = completion_data
        self._save_detailed_log()
        
        # åˆ›å»ºè®­ç»ƒæ€»ç»“æ–‡ä»¶
        summary_file = os.path.join(self.log_dir, "training_summary.txt")
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 50 + "\n")
            f.write("è®­ç»ƒå®Œæˆæ€»ç»“\n")
            f.write("=" * 50 + "\n")
            f.write(f"å¼€å§‹æ—¶é—´: {self.training_data['start_time']}\n")
            f.write(f"ç»“æŸæ—¶é—´: {completion_data['end_time']}\n")
            f.write(f"æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} ç§’\n")
            f.write(f"æ€»epochæ•°: {completion_data['total_epochs']}\n")
            f.write(f"æœ€ç»ˆBLEUåˆ†æ•°: {final_bleu:.4f}\n")
            f.write(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {model_path}\n")
            f.write(f"æŒ‡æ ‡æ–‡ä»¶: {self.metrics_file}\n")
            f.write(f"è¯¦ç»†æ—¥å¿—: {self.detailed_log}\n")
        
        print(f"ğŸ“‹ è®­ç»ƒæ€»ç»“å·²ä¿å­˜åˆ°: {summary_file}")
    
    def _save_detailed_log(self):
        """ä¿å­˜è¯¦ç»†çš„JSONæ—¥å¿—"""
        with open(self.detailed_log, 'w', encoding='utf-8') as f:
            json.dump(self.training_data, f, ensure_ascii=False, indent=2)
    
    def get_metrics_file(self):
        """è·å–æŒ‡æ ‡CSVæ–‡ä»¶è·¯å¾„"""
        return self.metrics_file
    
    def get_detailed_log_file(self):
        """è·å–è¯¦ç»†æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
        return self.detailed_log 